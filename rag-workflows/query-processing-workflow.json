{
  "name": "PAIGE Query Processing Workflow",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "paige-rag/process-query",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-query",
      "name": "Query Processing Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "paige-rag-process-query"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "validate-query",
              "leftValue": "={{ $json.query }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "isNotEmpty"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "validate-query",
      "name": "Validate Query",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "text-embedding-3-small"
            },
            {
              "name": "input",
              "value": "={{ $json.query }}"
            }
          ]
        },
        "options": {}
      },
      "id": "create-query-embedding",
      "name": "Create Query Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [680, 300],
      "credentials": {
        "openAiApi": {
          "id": "openai-api-key",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "url": "https://{{ $env.RAG_VECTOR_DB_INDEX_NAME }}.svc.{{ $env.RAG_VECTOR_DB_ENVIRONMENT }}.pinecone.io/query",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Api-Key",
              "value": "={{ $env.RAG_VECTOR_DB_API_KEY }}"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "vector",
              "value": "={{ $json.data[0].embedding }}"
            },
            {
              "name": "top_k",
              "value": "5"
            },
            {
              "name": "include_metadata",
              "value": "true"
            },
            {
              "name": "filter",
              "value": "={{ $json.user_id ? { \"user_id\": { \"$eq\": $json.user_id } } : {} }}"
            }
          ]
        },
        "options": {}
      },
      "id": "search-pinecone",
      "name": "Search Pinecone",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [900, 300]
    },
    {
      "parameters": {
        "jsCode": "// Prepare context for OpenAI\nconst query = $input.first().json.query;\nconst searchResults = $input.first().json.search_results;\nconst userDocument = $input.first().json.user_document || '';\n\n// Combine relevant chunks into context\nconst context = searchResults.matches.map(match => \n  `Source: ${match.metadata.source}\\nContent: ${match.metadata.content}`\n).join('\\n\\n');\n\n// Create the prompt\nconst prompt = `You are PAIGE, an AI wedding planning assistant. Use the following knowledge base and user document to answer the user's question.\n\nKnowledge Base Context:\n${context}\n\nUser Document:\n${userDocument}\n\nUser Question: ${query}\n\nPlease provide a helpful, accurate answer based on the knowledge base and user document. If the information isn't available, say so clearly.`;\n\nreturn [{\n  json: {\n    prompt: prompt,\n    query: query,\n    context_sources: searchResults.matches.map(m => m.metadata.source),\n    context_scores: searchResults.matches.map(m => m.score)\n  }\n}];"
      },
      "id": "prepare-context",
      "name": "Prepare Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 300]
    },
    {
      "parameters": {
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "gpt-4"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": \"{{ $json.prompt }}\"}]"
            },
            {
              "name": "max_tokens",
              "value": "1000"
            },
            {
              "name": "temperature",
              "value": "0.7"
            }
          ]
        },
        "options": {}
      },
      "id": "generate-response",
      "name": "Generate Response",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1340, 300],
      "credentials": {
        "openAiApi": {
          "id": "openai-api-key",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Format the final response\nconst openaiResponse = $input.first().json;\nconst context = $input.first().json.context_data;\n\nconst response = {\n  success: true,\n  answer: openaiResponse.choices[0].message.content,\n  sources: context.context_sources,\n  confidence_scores: context.context_scores,\n  query: context.query,\n  timestamp: new Date().toISOString(),\n  model_used: 'gpt-4',\n  rag_enabled: true\n};\n\nreturn [{ json: response }];"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "id": "success-response",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1780, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ {\n  \"success\": false,\n  \"error\": \"Invalid input: query is required\",\n  \"timestamp\": new Date().toISOString()\n} }}"
      },
      "id": "error-response",
      "name": "Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [680, 500]
    }
  ],
  "connections": {
    "Query Processing Webhook": {
      "main": [
        [
          {
            "node": "Validate Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Query": {
      "main": [
        [
          {
            "node": "Create Query Embedding",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Query Embedding": {
      "main": [
        [
          {
            "node": "Search Pinecone",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Pinecone": {
      "main": [
        [
          {
            "node": "Prepare Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Context": {
      "main": [
        [
          {
            "node": "Generate Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Response": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [
    {
      "createdAt": "2024-01-01T00:00:00.000Z",
      "updatedAt": "2024-01-01T00:00:00.000Z",
      "id": "paige-rag",
      "name": "PAIGE RAG"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2024-01-01T00:00:00.000Z",
  "versionId": "1"
}
